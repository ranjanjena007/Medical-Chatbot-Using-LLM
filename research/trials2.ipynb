{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try question answer system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers\n",
    "from langchain.chains import RetrievalQA\n",
    "from pinecone import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download embedding model\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = \"bb77b29f-7fe6-4390-9510-cec577216f50\"\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)  \n",
    "\n",
    "index_name=\"medical-chatbot\"\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=CTransformers(model=\"\\\\Users\\\\Ranjan Jena\\\\Desktop\\\\Work\\\\GENAI\\\\Projects\\\\Medical-Chatbot-Using-LLM\\\\model\\\\llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    "                  model_type=\"llama\",\n",
    "                  config={'max_new_tokens':512,\n",
    "                          'temperature':0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retriver_results(query, top_res):\n",
    "    # create the query vector\n",
    "    xq = embeddings.embed_query(query)\n",
    "    print(f\"embeddings {len(xq)}\")\n",
    "    # now query\n",
    "    xc = index.query(vector=xq, top_k=top_res, include_metadata=True, namespace=\"real\", include_values=True)\n",
    "\n",
    "    contexts = []\n",
    "    contexts = contexts + [\n",
    "            x['metadata']['text'] for x in xc['matches']\n",
    "        ]\n",
    "    \n",
    "    querydocs = []\n",
    "    from langchain.docstore.document import Document\n",
    "\n",
    "    for eachcont in contexts:\n",
    "        doc =  Document(page_content=eachcont, metadata={\"source\": \"local\"})\n",
    "        querydocs.append(doc)\n",
    "\n",
    "    return querydocs, \"\".join(contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "chain=load_qa_chain(llm,chain_type=\"stuff\")\n",
    "\n",
    "# pass result chunk after similarity search to question answer chain to get output\n",
    "def retrieve_answers(query):\n",
    "    querydocs, context = retriver_results(query,3)\n",
    "    response=chain.run(input_documents=querydocs,question=query)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Acne is a common skin disease characterized by pimples on the face, chest, and back. It occurs when the pores of the skin become clogged with oil, dead skin cells, and bacteria.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_query = \"What are Acne?\"\n",
    "retrieve_answers(our_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try 2 with prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT=PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "# PROMPT.format(context=context,question=question)\n",
    "# chain_type_kwargs={\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "chain=load_qa_chain(llm,chain_type=\"stuff\")\n",
    "\n",
    "# pass result chunk after similarity search to question answer chain to get output\n",
    "def retrieve_answers(query):\n",
    "    querydocs,context = retriver_results(query,2)\n",
    "    input_prompts = PROMPT.format(context=context,question=query)\n",
    "    # response=chain.run(input_documents=querydocs,question=input_prompts)\n",
    "    response=llm(input_prompts)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The best way to resolve pimples is by practicing good hygiene, using gentle skin care products, and avoiding picking or squeezing them. It's also important to see a dermatologist if the pimples are severe or persistent.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_query = \"How to resolve pipmples?\"\n",
    "retrieve_answers(our_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medicalchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
